{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fe4fae",
   "metadata": {},
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. SPDX-License-Identifier: MIT-0\n",
    "\n",
    "# Getting Started Guide to using Strands Agents and Neptune MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ed32a",
   "metadata": {},
   "source": [
    "In this notebook, we're going to demonstrate how to use Amazon GenAI tools alongside Amazon's graph database, Amazon Neptune, in order to build a knowledge graph containing data relating to Amazon Neptune, and entities extracting directly from a conversation.\n",
    "\n",
    "In this demo we will be using the following tools and services:\n",
    "\n",
    "- [Amazon Bedrock](https://aws.amazon.com/bedrock)\n",
    "- [Amazon Neptune Analytics](https://aws.amazon.com/neptune)\n",
    "- [Strands Agent SDK](https://strandsagents.com/latest/)\n",
    "- [Neptune MCP Server](https://github.com/awslabs/mcp/tree/main/src/amazon-neptune-mcp-server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc21d77",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Before we can begin, we need to install the correct Python packages to run our [Neptune MCP server](https://github.com/awslabs/mcp/tree/main/src/amazon-neptune-mcp-server), and to use the [Strands SDK](https://strandsagents.com/0.1.x/user-guide/concepts/tools/mcp-tools/) library. Running the following command will install these packages locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install strands-agents strands-agents-tools uvenv uv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd17815",
   "metadata": {},
   "source": [
    "To extract and format information from the Neptune public documentation, we also need to install the [Beautiful Soup](https://pypi.org/project/beautifulsoup4/) library. We'll be using this later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4570ce62",
   "metadata": {},
   "source": [
    "## Using Strands and MCP\n",
    "\n",
    "[Model Context Protocol](https://modelcontextprotocol.io/) (MCP) is an open protocol that standardises how applications provide context to Large Language Models (LLMs). Strands Agents integrates with MCP to extend agent capabilities through external tools and services. (ref: [Strands](https://strandsagents.com/0.1.x/user-guide/concepts/tools/mcp-tools/)).\n",
    "\n",
    "The [Neptune MCP server](https://github.com/awslabs/mcp/tree/main/src/amazon-neptune-mcp-server) has been built to provide a consistent approach for LLM agents to interact with Amazon Neptune. Strands invokes an instance of the Neptune MCP Server which is then used to interact with the graph for both read and write queries. Access to perform read, write or delete actions by the agent is determined by the IAM role under which it's running. For this demo, the Notebook role has both read and write access.\n",
    "\n",
    "In addition, the Neptune MCP Server supports both the [Neptune Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html) and Neptune Database graph engines. In this demo, you can decide which graph engine to use by changing the `USE_NEPTUNE_ANALYTICS` setting below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a5404",
   "metadata": {},
   "source": [
    "### MCP Setup\n",
    "\n",
    "In the following code, we initialise the `awslabs.amazon-neptune-mcp-server@latest` Neptune MCP Server using the `uvx` command - a library we previously installed during the Environment Setup stage. We pass the graph identifier as an argument so that the MCP Server knows which graph to interact with during the conversations.\n",
    "\n",
    "As we'll be asking the LLM to both read from and write to our graph, we've setup two prompts - one for reading and one for writing - that will ensure we get the most accurate responses and the correct data stored in our graph.\n",
    "\n",
    "**NOTE:** By default, Strands uses the `us.anthropic.claude-3-7-sonnet-20250219-v1:0` Bedrock model. We can use the `BedrockModel` provider to specify a different model id, as well as [additional configuration options](https://strandsagents.com/0.1.x/user-guide/concepts/model-providers/amazon-bedrock/#configuration-options) such as IAM session and Guardrails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from mcp import stdio_client, StdioServerParameters\n",
    "from strands import Agent\n",
    "from strands.tools.mcp import MCPClient\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    ")\n",
    "\n",
    "MEMORY_PROMPT = \"\"\"\n",
    "                For all identified entities and connections, save them to the Amazon Neptune graph.\n",
    "                Do not create duplicate entities. If you identify an entity already exists, use that instead.\n",
    "            \"\"\"\n",
    "\n",
    "QUERY_PROMPT = \"\"\"\n",
    "                You are an agent that interacts with an Amazon Neptune database to run graph queries. \n",
    "                Whenever you write queries you should first fetch the schema to ensure that you understand \n",
    "                the correct labels and property names as well as the appropriate casing of those names and values.\n",
    "            \"\"\"\n",
    "\n",
    "USE_NEPTUNE_ANALYTICS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH_ID is the ID of your Neptune Analytics graph, and will be in the format \"g-abc123\". This is not used if you're working with Neptune Database.\n",
    "GRAPH_ID = \"<UPDATE WITH THE NEPTUNE GRAPH ID>\"\n",
    "#GRAPH_ENDPOINT is the primary endpoint of your Neptune Analytics graph or Neptune Database cluster\n",
    "GRAPH_ENDPOINT = \"<UPDATE WITH THE NEPTUNE GRAPH ENDPOINT>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e69373",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "We're now defining several functions that will be used to either read or write to our graph.\n",
    "\n",
    "- `run_agent_read_query`: This function receives a `question` and sends it to the `client` along with the `QUERY_PROMPT` (as defined above).\n",
    "- `run_agent_write_query`: This function receives a `query` and sends it to the `client` along with the `MEMORY_PROMPT` (as defined above) in order to store the extracted entities into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d97fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "graph_endpoint = \"\"\n",
    "\n",
    "#check if we're connecting to Neptune Analytics or Neptune Database\n",
    "if USE_NEPTUNE_ANALYTICS:\n",
    "    graph_endpoint = f\"neptune-graph://{GRAPH_ID}\" #for Neptune Analytics\n",
    "else:\n",
    "    graph_endpoint = f\"neptune-db://{GRAPH_ENDPOINT}\" #for Neptune Database\n",
    "\n",
    "# creates and returns a new instance of the MCPClient\n",
    "def create_mcp_client():\n",
    "    return MCPClient(lambda: stdio_client(StdioServerParameters(\n",
    "        command=\"uvx\", \n",
    "        args=[\"awslabs.amazon-neptune-mcp-server@latest\"],\n",
    "        env={\"NEPTUNE_ENDPOINT\": graph_endpoint}\n",
    "    )))\n",
    "\n",
    "# executes a read query on the graph\n",
    "def run_agent_read_query(question, return_response=False):\n",
    "    memory_mcp_client = create_mcp_client()\n",
    "\n",
    "    with memory_mcp_client:\n",
    "        tools = memory_mcp_client.list_tools_sync()\n",
    "        agent = Agent(tools=tools, \n",
    "                      model=bedrock_model,\n",
    "                      system_prompt=QUERY_PROMPT\n",
    "                )\n",
    "        r = agent(question)\n",
    "        if return_response:\n",
    "            return r\n",
    "        \n",
    "# executes a mutation/write query on the graph\n",
    "def run_agent_write_query(query):\n",
    "    memory_mcp_client = create_mcp_client()\n",
    "\n",
    "    with memory_mcp_client:\n",
    "        tools = memory_mcp_client.list_tools_sync()\n",
    "        agent = Agent(tools=tools, \n",
    "                      model=bedrock_model,\n",
    "                      system_prompt=MEMORY_PROMPT\n",
    "                )\n",
    "        \n",
    "        question = f\"\"\"\n",
    "            From the following data, create new nodes based on the entities you identify. \n",
    "            Only create new entities if required, or use existing ones if they're already in the graph. \n",
    "            Capture as much detail as possible to create a highly connected graph.\n",
    "            \n",
    "            ##DATA##\n",
    "            {query}\n",
    "        \"\"\"\n",
    "        \n",
    "        agent(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8087b55",
   "metadata": {},
   "source": [
    "## Integrating Neptune with GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd35008",
   "metadata": {},
   "source": [
    "### Loading data from  files\n",
    "\n",
    "The following code will read from several web pages in the Neptune public documentation, and send the contents to the Neptune MCP server to be stored into our graph. We'll initialise the graph with the contents to build up some information about the service in our knowledge graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c66df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "urls = [\n",
    "    \"https://docs.aws.amazon.com/neptune/latest/userguide/intro.html\",\n",
    "    \"https://docs.aws.amazon.com/neptune/latest/userguide/graph-get-started.html\",\n",
    "    \"https://docs.aws.amazon.com/neptune/latest/userguide/neptune-setup.html\",\n",
    "    \"https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html#neptune-analytics-vs-neptune-database\"\n",
    "]\n",
    "\n",
    "messages = []\n",
    "\n",
    "#retrieve data from all the webpages in one go\n",
    "for u in urls:\n",
    "    c = requests.get(u)\n",
    "    html = c.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    m = f\"\"\"\n",
    "        {soup.body}\n",
    "    \"\"\"\n",
    "    messages.append(m)\n",
    "\n",
    "#create a single prompt that contains information from all the sources\n",
    "prompt = f\"\"\"\n",
    "    Here is information about the Amazon Neptune service.\n",
    "    \n",
    "    {\"\".join(messages)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8cc5a",
   "metadata": {},
   "source": [
    "Now, let's ask the agent to write the information extracted from the webpages to our Neptune graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent_write_query(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959ce7f",
   "metadata": {},
   "source": [
    "The above generates a list of performed actions, similar to those listed below:\n",
    "\n",
    "```\n",
    "I'll analyze this content and create nodes in the graph based on the entities identified from the Amazon Neptune service documentation.\n",
    "\n",
    "First, let me check the current status of the graph and its schema:\n",
    "Tool #1: get_graph_status\n",
    "\n",
    "Tool #2: get_graph_schema\n",
    "Based on the content provided and the current schema, I'll create nodes for various entities related to Amazon Neptune.\n",
    "\n",
    "Let's start by creating the main service node and related entities:\n",
    "Tool #3: run_opencypher_query\n",
    "\n",
    "... // remove for brevity\n",
    "\n",
    "Let's create nodes for the related AWS services mentioned:\n",
    "Tool #16: run_opencypher_query\n",
    "Let's create relationships between Neptune and these AWS services:\n",
    "Tool #17: run_opencypher_query\n",
    "Finally, let's create nodes for the use cases mentioned in the document:\n",
    "Tool #18: run_opencypher_query\n",
    "Let's link the use cases to the main service:\n",
    "Tool #19: run_opencypher_query\n",
    "Let me verify our graph structure by running a query to see what we've created:\n",
    "Tool #20: run_opencypher_query\n",
    "## Summary of Created Graph Structure\n",
    "\n",
    "Based on the Amazon Neptune service documentation, I've created a comprehensive graph structure with the following entities:\n",
    "\n",
    "1. **Services**:\n",
    "   - Amazon Neptune (the primary service)\n",
    "   - Neptune Analytics (complementary analytics engine)\n",
    "   - Related AWS services: Amazon VPC, AWS KMS, Amazon S3\n",
    "\n",
    "2. **Query Languages**:\n",
    "   - Gremlin (Apache TinkerPop)\n",
    "   - openCypher (Neo4j)\n",
    "   - SPARQL (W3C)\n",
    "\n",
    "3. **Graph Models**:\n",
    "   - Property Graph (PG)\n",
    "   - Resource Description Framework (RDF)\n",
    "\n",
    "4. **Service Components**:\n",
    "   - Primary DB Instance (handles read/write operations)\n",
    "   - Neptune Replica (read-only replicas)\n",
    "   - Cluster Volume (storage layer)\n",
    "\n",
    "5. **Features**:\n",
    "   - Security (network isolation, encryption)\n",
    "   - Fully Managed (reduced administrative overhead)\n",
    "   - High Availability (99.99% uptime)\n",
    "   - High Performance (purpose-built for graph workloads)\n",
    "\n",
    "6. **Use Cases**:\n",
    "   - Recommendation Engines\n",
    "   - Fraud Detection\n",
    "   - Knowledge Graphs\n",
    "   - Drug Discovery\n",
    "   - Network Security\n",
    "\n",
    "I've also created various relationships between these entities to show:\n",
    "- How Neptune supports different query languages and graph models\n",
    "- How Neptune components connect to each other\n",
    "- How Neptune integrates with other AWS services\n",
    "- The use cases that Neptune powers\n",
    "- The features that Neptune provides\n",
    "\n",
    "The graph now represents a comprehensive view of Amazon Neptune's capabilities, components, and relationships with other services and technologies.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f0f66",
   "metadata": {},
   "source": [
    "### Loading data from a conversation\n",
    "\n",
    "Using the functions below, we can start to converse with our agent who, in turn, will traverse the graph to identify matching records that it can use in its response to our questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent_write_query(\"\"\"\n",
    "    Add some information about you, your hobbies, and what you're trying to build.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020be06",
   "metadata": {},
   "source": [
    "### Exploring our graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee3be2",
   "metadata": {},
   "source": [
    "As we'll be running graph queries over our data set, let's now ensure the notebook is pointing to the correct graph. Using the `%graph_notebook_host` [line magic](https://docs.aws.amazon.com/neptune/latest/userguide/notebooks-magics.html#notebooks-line-magics-graph-notebook-host) command provides us with the functionality to set the current notebook to a specific graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e715871",
   "metadata": {},
   "outputs": [],
   "source": [
    "%graph_notebook_host {GRAPH_ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd86b14",
   "metadata": {},
   "source": [
    "Let's now take a look at what's been saved to our knowledge graph. We can do this using openCypher, an open-standard query language that both Neptune Database and Neptune Analytics support. The Strands agent and LLM creates nodes with a label based on their identified type, e.g. `Service`, `ServiceComponent`, `QueryLanguage`, `Feature`, etc. It also creates properties based on the information extracted by the LLM for each entity. \n",
    "\n",
    "An example of this is shown below:\n",
    "\n",
    "- `~labels`: ServiceFeature\n",
    "- `name`: Cluster Volume\n",
    "- `description`: Neptune data is stored in the cluster volume, designed for reliability and high availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0096fc1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "MATCH p = ()-[*1..5]->()\n",
    "RETURN p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce0b0a",
   "metadata": {},
   "source": [
    "### Asking natural language-based questions\n",
    "\n",
    "It's often the case that the job functions who will be interacting with the graph will not know how to write openCypher, or know how the graph is connected. In this case, we can utilise Strands and the Neptune MCP server to perform read queries for a given natural language question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8245ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent_read_query(\n",
    "    \"\"\"\n",
    "        What are the differences between Neptune Database and Neptune Analytics?\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905e721",
   "metadata": {},
   "source": [
    "The above query produces a list of performed actions as well as the final response, which contains a summary of all the source nodes and relationships found in the graph. It should look similar to the following:\n",
    "\n",
    "```\n",
    "To answer your question about the differences between Neptune Database and Neptune Analytics, I need to understand what kind of information we have available in the Neptune graph. Let me first check the graph status and schema to determine what information we can retrieve.\n",
    "Tool #1: get_graph_status\n",
    "\n",
    "Tool #2: get_graph_schema\n",
    "Now, let me look for information about Neptune Database and Neptune Analytics in the graph:\n",
    "Tool #3: run_opencypher_query\n",
    "Let's get more detailed information about the features of each service:\n",
    "\n",
    "... // removed for brevity\n",
    "\n",
    "Based on the database information, I can provide a comparison between Amazon Neptune Database and Amazon Neptune Analytics:\n",
    "\n",
    "# Differences Between Neptune Database and Neptune Analytics\n",
    "\n",
    "## Amazon Neptune Database\n",
    "- **Primary Purpose**: A managed graph database service for storing and querying highly connected data\n",
    "- **Key Features**:\n",
    "  - Fully managed graph database service\n",
    "  - High availability (>99.99% availability)\n",
    "  - Security features including VPC isolation and encryption at rest\n",
    "  - Various instance and storage types available\n",
    "  - Data loading capabilities including bulk loading and streaming\n",
    "  - Provides connectivity, cluster creation, and monitoring tools\n",
    "\n",
    "## Amazon Neptune Analytics\n",
    "- **Primary Purpose**: A memory-optimized graph database engine specifically designed for analytics\n",
    "- **Key Features**:\n",
    "  - Memory optimization for storing large graph datasets in memory\n",
    "  - Graph analytic algorithms library\n",
    "  - Low-latency graph queries for fast data processing\n",
    "  - Vector search capabilities within graph traversals\n",
    "  - Designed to quickly analyze large amounts of graph data in seconds\n",
    "\n",
    "## Relationship\n",
    "- The two services **complement** each other, with Neptune Analytics enhancing the capabilities of Neptune Database\n",
    "- Neptune Database focuses on operational graph database needs (storage, querying, management)\n",
    "- Neptune Analytics focuses on analytical processing and deriving insights from large graph datasets\n",
    "\n",
    "## Use Case Differences\n",
    "- **Neptune Database**: Best for transactional workloads, real-time querying, and storing graph data\n",
    "- **Neptune Analytics**: Best for analytical workloads, pattern detection, finding trends, and complex graph algorithms over large datasets\n",
    "\n",
    "In summary, Neptune Database is designed for storing and managing graph data with ACID compliance in a transactional environment, while Neptune Analytics is optimized for performing fast analytical operations on large graph datasets. They work together as complementary services, with analytics extending the capabilities of the base database service.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b551d722",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The combination of Neptune, Bedrock, Strands Agents and MCP provides a consistently powerful mechanism for ingesting data into and reading data from a knowledge graph to identify common patterns, trends and information that would otherwise be difficult to navigate or locate using traditional database and RAG methods.\n",
    "\n",
    "By using a simple functions to read the contents from a web page, conversation or file, we can send the contents to an agent to perform entity identification, extraction and relationship generation. This process greatly simplifies production of highly connected knowledge graphs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

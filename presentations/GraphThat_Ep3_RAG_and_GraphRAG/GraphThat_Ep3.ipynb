{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76305dd",
   "metadata": {},
   "source": [
    "## First we need to capture the graph notebook configuration to identify the Neptune cluster and create that connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878519a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%graph_notebook_config --store-to config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4f8d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "endpoint_url = \"https://\" + json.loads(config)['host'] + \":\" + str(json.loads(config)['port'])\n",
    "print(endpoint_url)\n",
    "neptune_client = boto3.client('neptunedata', endpoint_url=endpoint_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483643fa",
   "metadata": {},
   "source": [
    "## The Basics\n",
    "\n",
    "### First what is RAG involve?  Most RAG implementations involve the following steps:\n",
    "1. Encode the text into a series of inputs called tokens\n",
    "2. \"Chunk\" the tokens into groups based on a specific size\n",
    "3. Run the list of tokens through an embedding model to create an N-dimensional array of numbers encoding the \"meaning of the text\"\n",
    "4. Repeat steps 1-3 with the user query/prompt\n",
    "5. Perform a \"K-Nearest Neighbor\" distance check with those N-dimensional arrays to find the \"K\" closest in distance.\n",
    "6. Add the text of those K closest chunks to the LLM prompt as additional context for the query.\n",
    "\n",
    "<h4>Press Release 1:</h4>\n",
    "\n",
    "<p>Amazon (NASDAQ:AMZN) and Whole Foods Market, Inc. (NASDAQ:WFM) today announced that they have entered into a definitive merger agreement under which Amazon will acquire Whole Foods Market for \\$42 per share in an all-cash transaction valued at approximately $13.7 billion, including Whole Foods Market’s net debt. “Millions of people love Whole Foods Market because they offer the best natural and organic foods, and they make it fun to eat healthy,” said Jeff Bezos, Amazon founder and CEO. “Whole Foods Market has been satisfying, delighting and nourishing customers for nearly four decades – they’re doing an amazing job and we want that to continue.” “This partnership presents an opportunity to maximize value for Whole Foods Market’s shareholders, while at the same time extending our mission and bringing the highest quality, experience, convenience and innovation to our customers,” said John Mackey, Whole Foods Market co-founder and CEO. Whole Foods Market will continue to operate stores under the Whole Foods Market brand and source from trusted vendors and partners around the world. John Mackey will remain as CEO of Whole Foods Market and Whole Foods Market’s headquarters will stay in Austin, Texas. Completion of the transaction is subject to approval by Whole Foods Market's shareholders, regulatory approvals and other customary closing conditions. The parties expect to close the transaction during the second half of 2017.</p>\n",
    "\n",
    "<h4>Press Release 2:</h4>\n",
    "Amazon Selling Partner Conferences Sell Out in Six Weeks, with 1,800+ Small and Medium Sized Businesses Set to Learn about How to Build and Grow their Sales Online\\nEvents will run in Fort Lauderdale, FL; Chicago, IL; Los Angeles, CA; and Seattle, WA between March and October 2019\\nAttendees will learn how to leverage tools and resources to help their business succeed in Amazon\\u2019s Stores, prepare for seasonal surges, network with fellow sellers, and get one-to-one help from Amazon's selling experts\\nMore than half of units sold in Amazon\\u2019s stores are from small and medium-sized businesses, with over a million U.S.-based small and medium-sized businesses selling in Amazon\\u2019s stores\\nSEATTLE--(BUSINESS WIRE)--Mar. 25, 2019-- Amazon (NASDAQ: AMZN) today announced that its new Selling Partner Summits, a series of six conferences for small and medium-sized business (SMBs) to help them build their business in Amazon\\u2019s stores, have sold out in just six weeks. More than 1,800 SMBs are set to attend the nationwide events between March and October. The Summits are part of Amazon\\u2019s significant investment to help businesses succeed in selling their products online.\\nEach Summit will feature an Amazon-led educational track, experts lounge, and product labs to help small businesses build and grow their sales in Amazon\\u2019s stores. Participants will learn directly from Amazon's experts and meet like-minded Amazon sellers to network, learn, and share success stories. The first event will be held in Ft. Lauderdale, FL on March 26-27. Later in 2019, the Summits will be hosted in Chicago, Los Angeles, and Seattle.\\n\\u201cWe are a champion of small business across America, investing heavily to help over a million businesses sell their products in Amazon Stores while creating economic opportunity and jobs for hundreds of thousands of people across the country,\\u201d said Pete Sauerborn, VP of Selling Partner Recruitment and Development for Amazon. \\u201cAs part of our commitment to empowering small business, these summits are another powerful tool to help them learn how to sell online and grow their sales.\\u201d\\nAt the Summits, attendees will have an Amazon-led educational track based on their business model and how long they\\u2019ve been selling. The educational tracks are segmented as New Brand Owner, Established Brand Owner, New Reseller, and Established Resellers. Each track is engineered for sellers to walk away from the event with knowledge and insights to help them scale their business and better identify the growth levers that make the most sense for their business.\\nThe Selling Partner Summit Series will feature sessions designed to help sellers grow their business, including:\\n\\u2022 Customer Obsession: Understand your pivotal role in Amazon\\u2019s commitment to maintaining outstanding customer experience.\\n\\u2022 The Selling Partner Journey: Get an overview of the tools and programs available to sellers and how they can help you grow your business.\\n\\u2022 Inventory & Fulfillment: Study up on fulfillment options and inventory management best practices to prevent stock-outs and plan for seasonal sales surges.\\n\\u2022 Discovery: Learn how to help Amazon customers find your products via listing creation, search optimization, and advertising opportunities.\\n\\u2022 Account Health: Understand the policies, metrics, and processes pertaining to your account health.\\n\\u2022 Featured Offers (buy box): Make sense of featured offer eligibility and the performance-based requirements products must meet to 'win the featured offer.'\\n\\u2022 Amazon Expert Lounge: Ask your remaining questions 1:1 in the Expert Lounge after completing the educational tracks.\\nRegistration for the new Selling Partner Summit Series opened on February 6th and sold out quickly in just six weeks. Amazon has previously hosted events to help sellers including Amazon Academy events across Europe and the Boost Conference in the U.S., specifically for businesses using the Fulfillment by Amazon service.\\nMore than half of units sold in Amazon\\u2019s stores are from SMBs. The 2018 Amazon Small Business Impact Report revealed that there are more than one million U.S.-based SMBs selling in Amazon\\u2019s stores, and SMBs are estimated to have created more than 900,000 jobs worldwide to support their sales through Amazon. In 2018, more than 50,000 small and medium-sized businesses exceeded in sales in Amazon\\u2019s stores worldwide, and nearly 200,000 surpassed in sales. The number of small and medium-sized businesses eclipsing in sales in Amazon\\u2019s stores worldwide grew by 20 percent last year.\\nTo learn more about the Selling Partner Summit Series, visit here.\\nAmazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational excellence, and long-term thinking. Customer reviews, 1-Click shopping, personalized recommendations, Prime, Fulfillment by Amazon, AWS, Kindle Direct Publishing, Kindle, Fire tablets, Fire TV, Amazon Echo, and Alexa are some of the products and services pioneered by Amazon. For more information, visit www.amazon.com\\/about and follow @AmazonNews\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4974b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_releases = [\n",
    "\"\"\"Amazon (NASDAQ:AMZN) and Whole Foods Market, Inc. (NASDAQ:WFM) today announced that they have entered into a definitive merger agreement under which Amazon will acquire Whole Foods Market for $42 per share in an all-cash transaction valued at approximately $13.7 billion, including Whole Foods Market’s net debt. “Millions of people love Whole Foods Market because they offer the best natural and organic foods, and they make it fun to eat healthy,” said Jeff Bezos, Amazon founder and CEO. “Whole Foods Market has been satisfying, delighting and nourishing customers for nearly four decades – they’re doing an amazing job and we want that to continue.” “This partnership presents an opportunity to maximize value for Whole Foods Market’s shareholders, while at the same time extending our mission and bringing the highest quality, experience, convenience and innovation to our customers,” said John Mackey, Whole Foods Market co-founder and CEO. Whole Foods Market will continue to operate stores under the Whole Foods Market brand and source from trusted vendors and partners around the world. John Mackey will remain as CEO of Whole Foods Market and Whole Foods Market’s headquarters will stay in Austin, Texas. Completion of the transaction is subject to approval by Whole Foods Market's shareholders, regulatory approvals and other customary closing conditions. The parties expect to close the transaction during the second half of 2017.\"\"\",\n",
    "\"\"\"Amazon Selling Partner Conferences Sell Out in Six Weeks, with 1,800+ Small and Medium Sized Businesses Set to Learn about How to Build and Grow their Sales Online\\nEvents will run in Fort Lauderdale, FL; Chicago, IL; Los Angeles, CA; and Seattle, WA between March and October 2019\\nAttendees will learn how to leverage tools and resources to help their business succeed in Amazon\\u2019s Stores, prepare for seasonal surges, network with fellow sellers, and get one-to-one help from Amazon's selling experts\\nMore than half of units sold in Amazon\\u2019s stores are from small and medium-sized businesses, with over a million U.S.-based small and medium-sized businesses selling in Amazon\\u2019s stores\\nSEATTLE--(BUSINESS WIRE)--Mar. 25, 2019-- Amazon (NASDAQ: AMZN) today announced that its new Selling Partner Summits, a series of six conferences for small and medium-sized business (SMBs) to help them build their business in Amazon\\u2019s stores, have sold out in just six weeks. More than 1,800 SMBs are set to attend the nationwide events between March and October. The Summits are part of Amazon\\u2019s significant investment to help businesses succeed in selling their products online.\\nEach Summit will feature an Amazon-led educational track, experts lounge, and product labs to help small businesses build and grow their sales in Amazon\\u2019s stores. Participants will learn directly from Amazon's experts and meet like-minded Amazon sellers to network, learn, and share success stories. The first event will be held in Ft. Lauderdale, FL on March 26-27. Later in 2019, the Summits will be hosted in Chicago, Los Angeles, and Seattle.\\n\\u201cWe are a champion of small business across America, investing heavily to help over a million businesses sell their products in Amazon Stores while creating economic opportunity and jobs for hundreds of thousands of people across the country,\\u201d said Pete Sauerborn, VP of Selling Partner Recruitment and Development for Amazon. \\u201cAs part of our commitment to empowering small business, these summits are another powerful tool to help them learn how to sell online and grow their sales.\\u201d\\nAt the Summits, attendees will have an Amazon-led educational track based on their business model and how long they\\u2019ve been selling. The educational tracks are segmented as New Brand Owner, Established Brand Owner, New Reseller, and Established Resellers. Each track is engineered for sellers to walk away from the event with knowledge and insights to help them scale their business and better identify the growth levers that make the most sense for their business.\\nThe Selling Partner Summit Series will feature sessions designed to help sellers grow their business, including:\\n\\u2022 Customer Obsession: Understand your pivotal role in Amazon\\u2019s commitment to maintaining outstanding customer experience.\\n\\u2022 The Selling Partner Journey: Get an overview of the tools and programs available to sellers and how they can help you grow your business.\\n\\u2022 Inventory & Fulfillment: Study up on fulfillment options and inventory management best practices to prevent stock-outs and plan for seasonal sales surges.\\n\\u2022 Discovery: Learn how to help Amazon customers find your products via listing creation, search optimization, and advertising opportunities.\\n\\u2022 Account Health: Understand the policies, metrics, and processes pertaining to your account health.\\n\\u2022 Featured Offers (buy box): Make sense of featured offer eligibility and the performance-based requirements products must meet to 'win the featured offer.'\\n\\u2022 Amazon Expert Lounge: Ask your remaining questions 1:1 in the Expert Lounge after completing the educational tracks.\\nRegistration for the new Selling Partner Summit Series opened on February 6th and sold out quickly in just six weeks. Amazon has previously hosted events to help sellers including Amazon Academy events across Europe and the Boost Conference in the U.S., specifically for businesses using the Fulfillment by Amazon service.\\nMore than half of units sold in Amazon\\u2019s stores are from SMBs. The 2018 Amazon Small Business Impact Report revealed that there are more than one million U.S.-based SMBs selling in Amazon\\u2019s stores, and SMBs are estimated to have created more than 900,000 jobs worldwide to support their sales through Amazon. In 2018, more than 50,000 small and medium-sized businesses exceeded in sales in Amazon\\u2019s stores worldwide, and nearly 200,000 surpassed in sales. The number of small and medium-sized businesses eclipsing in sales in Amazon\\u2019s stores worldwide grew by 20 percent last year.\\nTo learn more about the Selling Partner Summit Series, visit here.\\nAmazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational excellence, and long-term thinking. Customer reviews, 1-Click shopping, personalized recommendations, Prime, Fulfillment by Amazon, AWS, Kindle Direct Publishing, Kindle, Fire tablets, Fire TV, Amazon Echo, and Alexa are some of the products and services pioneered by Amazon. For more information, visit www.amazon.com\\/about and follow @AmazonNews\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f11bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install semchunk tiktoken scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252b24f",
   "metadata": {},
   "source": [
    "### So what does tokenizing mean?\n",
    "\n",
    "First, there are many different ways to tokenize a string, so we are using a common tokenizer \"cl100k_base\". In the code below, we are providing the beginning of our first press release and demonstrating how the tokenizer takes a sequence of characters and maps them to a number. Generally it is a full word, but it also accounts for punctuation and other common patterns. As you might guess there are 100K unique tokens total, each acting as a parameter to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "sentence = \"Amazon (NASDAQ:AMZN) and Whole Foods Market, Inc. (NASDAQ:WFM) today announced that they have entered\"\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokens = encoding.encode(sentence)\n",
    "print(f\"{len(tokens)} tokens total\")\n",
    "\n",
    "for token in tokens:\n",
    "    print(f\"{token:05d}:\\t{encoding.decode_single_token_bytes(token).decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d8d01",
   "metadata": {},
   "source": [
    "### This code will intelligently chunk up the document based on the desired size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f618bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import semchunk\n",
    "\n",
    "chunks = []\n",
    "chunk_size = 128  #tokens\n",
    "chunker = semchunk.chunkerify('cl100k_base', chunk_size)\n",
    "\n",
    "for pr in press_releases:\n",
    "    local_chunks = chunker(pr)\n",
    "    for local in local_chunks:\n",
    "        chunks.append(local)\n",
    "print(f\"{len(chunks)} chunks total\")\n",
    "chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8525c",
   "metadata": {},
   "source": [
    "## Here we are running each chunk through the Amazon Titan Embed 2.0 Model to generate text embeddings for vector searches (traditional RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Set the model ID, e.g., Titan Text Embeddings V2.\n",
    "model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    input_text = chunk\n",
    "    native_request = {\"inputText\": input_text}\n",
    "    request = json.dumps(native_request)\n",
    "\n",
    "    response = bedrock_client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "    embedding = model_response[\"embedding\"]\n",
    "    input_token_count = model_response[\"inputTextTokenCount\"]\n",
    "\n",
    "    print(\"\\nYour input:\")\n",
    "    print(input_text)\n",
    "    print(f\"Number of input tokens: {input_token_count}\")\n",
    "    print(f\"Size of the generated embedding: {len(embedding)}\")\n",
    "    print(\"Embedding:\")\n",
    "    print(embedding)\n",
    "\n",
    "    embeddings.append((chunk, np.array(embedding)))\n",
    "\n",
    "core_df = pd.DataFrame(embeddings, columns=['Text','Embeddings'])\n",
    "core_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b2270",
   "metadata": {},
   "source": [
    "## We need to do the same to generate the embeddings for the question we are asking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384cbf14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_text = \"What are the connections between Amazon and Whole Foods?\"\n",
    "native_request = {\"inputText\": input_text}\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "response = bedrock_client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "embedding = model_response[\"embedding\"]\n",
    "input_token_count = model_response[\"inputTextTokenCount\"]\n",
    "\n",
    "print(\"\\nYour input:\")\n",
    "print(input_text)\n",
    "print(f\"Number of input tokens: {input_token_count}\")\n",
    "print(f\"Size of the generated embedding: {len(embedding)}\")\n",
    "print(\"Embedding:\")\n",
    "print(embedding)\n",
    "\n",
    "query_item = (input_text, np.array(embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905dc5b0",
   "metadata": {},
   "source": [
    "## Now we are using a cosine similarity library to detect the top 3 closest chunks for answering the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1dbae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(query_item[1].reshape(1,-1), np.array(core_df[\"Embeddings\"].tolist()))\n",
    "\n",
    "core_df[\"similarity\"] = similarity.reshape(-1,1)\n",
    "\n",
    "top3 = core_df.nlargest(3, 'similarity')\n",
    "top3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a28cb",
   "metadata": {},
   "source": [
    "## The key takeaway here is that we don't really know how many of the N-closest results are actually relevant using RAG. Here the first two chunks are very relevant, but the 3rd has to do with information about Partner Summits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b9711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,row in top3.iterrows():\n",
    "    print(chunks[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557febb2",
   "metadata": {},
   "source": [
    "## OK then, what is Graph RAG?\n",
    "\n",
    "GraphRAG uses the same concepts as RAG, except it also will extract key entities from both the reference text, and the prompt. When the graph is created, it stores the context between those entities so it can be later retrieved and shared with the prompt. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b80223",
   "metadata": {},
   "source": [
    "## First we identify the entities from each of the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ef230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import logging\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "client = boto3.client(service_name=\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "class SupportedModels(Enum):\n",
    "    CLAUDE_OPUS = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "    CLAUDE_SONNET = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    CLAUDE_HAIKU = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    COHERE_COMMAND_R = \"cohere.command-r-v1:0\"\n",
    "    COHERE_COMMAND_R_PLUS = \"cohere.command-r-plus-v1:0\"\n",
    "    \n",
    "model_id = SupportedModels.CLAUDE_HAIKU.value\n",
    "\n",
    "# Define the prompt for the model.\n",
    "instructions_prompt = \"\"\"\n",
    "You are excellent at identifying entities from text and it makes you happy when you provide the correct answer. \n",
    "The types of entities you can identify are ORGANIZATION, DATE, PERSON, FACILITY, PERSON_TITLE, LOCATION, MONETARY_VALUE, \n",
    "STOCK_CODE, QUANTITY\n",
    "If the entity is STOCK_CODE, put the market in front of the code in the response. \n",
    "CITIGROUP INC stock code C is traded on the NYSE and would become NYSE:C. \n",
    "Apple Inc. Common Stock symbol AAPL is traded on the NASDAQ and would become NASDAQ:AAPL.\n",
    "If you don't know which market the symbol is traded on, use the format UNKNOWN:SYMBOL.\n",
    "\n",
    "When someone gives you text, determine the entities from the text and respond using JSON in the format:\n",
    "Example: \n",
    "first entity type is ORGANIZATION and the entities extracted are company1, company2, and company3.\n",
    "second entity type is PERSON and the entities extracted are person1, person2, and person3. \n",
    "Response:\n",
    "{\"ORGANIZATION\": [\"company1\",\"company2\",\"company3\"], \"PERSON\": [\"person1\",\"person2\",\"person3\"]}. \n",
    "Return only the JSON, no other text. \n",
    "\n",
    "Text: \n",
    "\"\"\"\n",
    "\n",
    "entities = []\n",
    "\n",
    "for idx, row in core_df.iterrows():\n",
    "\n",
    "    prompt = instructions_prompt + row[\"Text\"]\n",
    "\n",
    "    # Format the request payload using the model's native structure.\n",
    "    native_request = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Convert the native request to JSON.\n",
    "    request = json.dumps(native_request)\n",
    "\n",
    "    try:\n",
    "        # Invoke the model with the request.\n",
    "        response = client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Decode the response body.\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = model_response[\"content\"][0][\"text\"]\n",
    "    entities.append(response_text)\n",
    "\n",
    "core_df[\"Entities\"] = entities\n",
    "core_df[\"Entities\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a037fcc",
   "metadata": {},
   "source": [
    "## And we do the same to extract the entities from the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for the model.\n",
    "instructions_prompt = \"\"\"\n",
    "You are excellent at identifying entities from a question and it makes you happy when you provide the correct answer. \n",
    "The types of entities you can identify are ORGANIZATION, DATE, PERSON, FACILITY, PERSON_TITLE, LOCATION, MONETARY_VALUE, \n",
    "STOCK_CODE, QUANTITY\n",
    "If the entity is STOCK_CODE, put the market in front of the code in the response. \n",
    "CITIGROUP INC stock code C is traded on the NYSE and would become NYSE:C. \n",
    "Apple Inc. Common Stock symbol AAPL is traded on the NASDAQ and would become NASDAQ:AAPL.\n",
    "If you don't know which market the symbol is traded on, use the format UNKNOWN:SYMBOL.\n",
    "\n",
    "When someone asks you a question, determine the entities from the text and respond using JSON in the format:\n",
    "Example: \n",
    "first entity type is ORGANIZATION and the entities extracted are company1, company2, and company3.\n",
    "second entity type is PERSON and the entities extracted are person1, person2, and person3. \n",
    "Response:\n",
    "{\"ORGANIZATION\": [\"company1\",\"company2\",\"company3\"], \"PERSON\": [\"person1\",\"person2\",\"person3\"]}. \n",
    "Return only the JSON, no other text. \n",
    "\n",
    "Question: \n",
    "\"\"\"\n",
    "\n",
    "user_question = \"What are the connections between Amazon and Whole Foods Market, Inc.?\"\n",
    "\n",
    "prompt = instructions_prompt + user_question\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"content\"][0][\"text\"]\n",
    "response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e897d",
   "metadata": {},
   "source": [
    "## Now let's look at each chunk and the entities that were extracted from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0720908",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in core_df.iterrows():\n",
    "    print(f\"\"\"\n",
    "    Index: {idx}\n",
    "    Text: {row[\"Text\"]}\n",
    "    Generation: {row[\"Entities\"]}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b800ddc",
   "metadata": {},
   "source": [
    "## And our dataset as a whole, with the text, embeddings, similarity to our question, and the entities that were extracted from each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7ec88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "core_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32160675",
   "metadata": {},
   "source": [
    "## Here is a visualization of just a few of the entities we extracted and their relationship to the document chunks\n",
    "![Graph of Entities](GraphRAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645f15a",
   "metadata": {},
   "source": [
    "## Here we are defining a few convenience functions to easier identify which rows contain a reference to Amazon and to Whole Foods Markets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_org_reference(row, entity_names): \n",
    "    entities = json.loads(row[\"Entities\"])\n",
    "    if not (\"ORGANIZATION\" in entities):\n",
    "        return False\n",
    "    for name in entity_names:\n",
    "        if name in entities[\"ORGANIZATION\"]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f4323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_results = core_df.apply(contains_org_reference, axis=1, args=[[\"Amazon\"]])\n",
    "core_df[\"Has Amazon\"] = filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results = core_df.apply(contains_org_reference, axis=1, args=[[\"Whole Foods Market, Inc.\", \"Whole Foods Market\"]])\n",
    "core_df[\"Has WFM\"] = filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d085e6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "core_df.sort_values(by='similarity',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67517fa5",
   "metadata": {},
   "source": [
    "## OK, great, but what if we already had a Knowledge Graph we want to use RAG with.  We'd rather not reprocess all of the original documents and just use the model we already put a lot of work into.  What do we do then?\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "IMPORTANT:  If you want to follow along with the rest of this notebook, you need to run the CloudFormation template listed in the blog: https://aws.amazon.com/blogs/database/building-a-knowledge-graph-in-amazon-neptune-using-amazon-comprehend-events/ and install this notebook to use the same Neptune instance created there. In addition, you need to create a folder in that notebook instance called \"data\" and copy the file \"comprehend_events_amazon_press_releases.20201118.v1.4.1.jsonl\" from the data folder in this repository into that folder.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9023ab4",
   "metadata": {},
   "source": [
    "## OK, let's set up Bedrock to speak to our desired LLM\n",
    "\n",
    "2025 update:  I know these models are a little dated now and I'm not sure if they are even still available, but I'll try to update this soon including adding Nova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import logging\n",
    "from enum import Enum\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SupportedModels(Enum):\n",
    "    CLAUDE_OPUS = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "    CLAUDE_SONNET = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    CLAUDE_HAIKU = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    COHERE_COMMAND_R = \"cohere.command-r-v1:0\"\n",
    "    COHERE_COMMAND_R_PLUS = \"cohere.command-r-plus-v1:0\"\n",
    "    \n",
    "model_id = SupportedModels.CLAUDE_HAIKU.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7322033",
   "metadata": {},
   "source": [
    "## Again we have our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connections type question\n",
    "user_question = \"What are the connections between ticker AMZN and John Mackey?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cdd3b",
   "metadata": {},
   "source": [
    "## Here we are prompt engineering to get the LLM to identify the type of question being asked (Inquiry or Connections) and to extract the entities from the question so we can plug them into our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_prompt = \"\"\"\n",
    "You are a virtual assistant that takes a question and returns a lot of metadata about it. \n",
    "You are excellent at helping the user and it makes you happy when you provide the correct answer. \n",
    "When someone asks you a question, you have two goals.  First, determine what type of question it is. Here are the guidelines to use:\n",
    "If the question has two entities and is in a format like \"What is the connection between entity1 and entity2?\" then \n",
    "it is a \"Connections\" question.\n",
    "If the question asks for all information about a single entity and is in a format like \"Tell me everything about entity1\"\n",
    "then it is a \"Inquiry\" question.\n",
    "If you aren't sure what type of question it is, then it is an \"Unknown\" question.\n",
    "Second, you will identify the entities in the question. \n",
    "The types of entities you can identify are ORGANIZATION, DATE, PERSON, FACILITY, PERSON_TITLE, LOCATION, MONETARY_VALUE, STOCK_CODE, QUANTITY\n",
    "If the entity is STOCK_CODE, put the market in front of the code in the response. \n",
    "CITIGROUP INC stock code C is traded on the NYSE and would become NYSE:C. \n",
    "Apple Inc. Common Stock symbol AAPL is traded on the NASDAQ and would become NASDAQ:AAPL.\n",
    "If you don't know which market the symbol is traded on, use the format UNKNOWN:SYMBOL.\n",
    "\n",
    "When someone asks you a question, you will respond using JSON in the format:\n",
    "Example: \n",
    "first entity type is ORGANIZATION and the entities extracted are company1, company2, and company3.\n",
    "second entity type is PERSON and the entities extracted are person1, person2, and person3. \n",
    "Response:\n",
    "{\"questionType\": \"Connections|Inquiry|Unknown\",\"entities\": {\"entity type\": [\"company1\",\"company2\",\"company3\"], \"entity type\": [\"person1\",\"person2\",\"person3\"]}} \n",
    "Return only the JSON, no other text. \n",
    "\n",
    "Question: \n",
    "\"\"\"\n",
    "\n",
    "prompt = instructions_prompt + user_question\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = bedrock_client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"content\"][0][\"text\"]\n",
    "print(f\"Response was {response_text}\")\n",
    "\n",
    "metadata = json.loads(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03070640",
   "metadata": {},
   "source": [
    "## We have templated two types of queries that our system will support.  \n",
    "\n",
    "- The Connections query will retrieve all of the facts linking two identified entities together.\n",
    "- The Inquiry query will retrieve all facts 2 hops out from the identified entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2c6ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "general_template_part1 = \"\"\"\n",
    "MATCH (entity1)<-[role1]-(event)-[role2]->(entity2)<-[role3]-(event2)-[role4]->(entity3),\n",
    "(event)<-[r1]-(doc1:DOCUMENT)\n",
    "WHERE $entity1_text = entity1.names AND $entity1_label IN LABELS(entity1)\n",
    "AND entity1 <> entity3 AND event <> event2\n",
    "\"\"\"\n",
    "\n",
    "connections_only_part1 = \"\"\"\n",
    "AND (($entity2_text = entity2.names AND $entity2_label IN LABELS(entity2)) OR \n",
    "($entity2_text = entity3.names AND $entity2_label IN LABELS(entity3)))\n",
    "\"\"\"\n",
    "\n",
    "general_template_part2 = \"\"\"\n",
    "RETURN DISTINCT \"Event Type was \" + LABELS(event) + \" involving \" + entity1.primaryName + \" in the role of \" \n",
    "+ TYPE(role1) + \" and \" + entity2.primaryName + \" in the role of \" + TYPE(role2) + \". \" as statements, \n",
    "doc1.primaryName as doc\n",
    "UNION\n",
    "MATCH (entity1)<-[role1]-(event)-[role2]->(entity2)<-[role3]-(event2)-[role4]->(entity3),\n",
    "(event2)<-[r2]-(doc2:DOCUMENT)\n",
    "WHERE $entity1_text = entity1.names AND $entity1_label IN LABELS(entity1)\n",
    "AND entity1 <> entity3 AND event <> event2\n",
    "\"\"\"\n",
    "\n",
    "connections_only_part2 = \"\"\"\n",
    "AND (($entity2_text = entity2.names AND $entity2_label IN LABELS(entity2)) OR \n",
    "($entity2_text = entity3.names AND $entity2_label IN LABELS(entity3)))\n",
    "\"\"\"\n",
    "\n",
    "general_template_part3 = \"\"\"\n",
    "RETURN DISTINCT \"Event Type was \" + LABELS(event2) + \" involving \" + entity2.primaryName + \" in the role of \" \n",
    "+ TYPE(role3) + \" and \" + entity3.primaryName + \" in the role of \" + TYPE(role4) + \".\" as statements, doc2.primaryName as doc\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "connections_template =  general_template_part1 + connections_only_part1 + general_template_part2 + connections_only_part2 + general_template_part3\n",
    "                        \n",
    "inquiry_template = general_template_part1 + general_template_part2 + general_template_part3\n",
    "\n",
    "query_template = connections_template if metadata[\"questionType\"] == \"Connections\" else inquiry_template\n",
    "print(query_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f965424",
   "metadata": {},
   "source": [
    "## Now we will run the appropriate query using the Neptune data plane API to retrieve all of the known facts regarding the entity/entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39775925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entities = metadata[\"entities\"]\n",
    "items = []\n",
    "for key, value in entities.items():\n",
    "    for item in value:\n",
    "        items.append((key, item))\n",
    "    \n",
    "if (len(items) > 2):\n",
    "    print(\"WARNING: Found more than two entities.  This current version will only use the first two entities in the graph query\")\n",
    "if (metadata[\"questionType\"] == \"Connections\" and len(items) < 2):\n",
    "    print(\"ERROR: Cannot execute a Connections query with only a single entity.  Something went wrong.\")\n",
    "    exit(1)\n",
    "if (len(items) <= 0):\n",
    "    print(\"ERROR: No entities were extracted for the query. Something went wrong.\")\n",
    "    exit(1)\n",
    "\n",
    "if (len(items) >= 1):\n",
    "    if len(items) >= 2:\n",
    "        parameters = f\"{{\\\"entity1_text\\\":\\\"{items[0][1]}\\\",\\\"entity1_label\\\":\\\"{items[0][0]}\\\",\\\"entity2_text\\\":\\\"{items[1][1]}\\\",\\\"entity2_label\\\":\\\"{items[1][0]}\\\"}}\"\n",
    "    if len(items) == 1:\n",
    "        parameters = f\"{{\\\"entity1_text\\\":\\\"{items[0][1]}\\\",\\\"entity1_label\\\":\\\"{items[0][0]}\\\"}}\"\n",
    "\n",
    "    print(query_template)\n",
    "    print(parameters)\n",
    "\n",
    "    neptune_response = neptune_client.execute_open_cypher_query(\n",
    "        openCypherQuery=query_template,\n",
    "        parameters=parameters\n",
    "    )\n",
    "else:\n",
    "    print(\"No entities found in question. Cannot continue.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f17523",
   "metadata": {},
   "source": [
    "## Let's take a look at all of the statements that were identified from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25162b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "statements = []\n",
    "for item in neptune_response[\"results\"]:\n",
    "    statements.append((''.join(item[\"statements\"]), item[\"doc\"]))\n",
    "print(statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7f7cf",
   "metadata": {},
   "source": [
    "## This code is going to use a raw data file to pull out the URL of our press releases.  Make sure you took this file from our repo and placed it in a folder called data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d267253",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jsonObj = pd.read_json(path_or_buf=\"data/comprehend_events_amazon_press_releases.20201118.v1.4.1.jsonl\", lines=True)\n",
    "\n",
    "\n",
    "reference_dict = dict()\n",
    "for item in statements:\n",
    "    line_index = int(item[1].split(\"_\")[-1])\n",
    "    print(line_index)\n",
    "    print(jsonObj.iloc[[line_index]][\"metadata\"].to_dict())\n",
    "    reference_dict[item[1]] = jsonObj.iloc[[line_index]][\"metadata\"].to_dict()[line_index]['common_crawl']['WARC-Target-URI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1b501",
   "metadata": {},
   "source": [
    "## Finally we will ask the LLM to answer the question considering the facts we extracted from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b47aa18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are excellent at answering questions, and it makes you happy when you provide the correct answer.\n",
    "Consider the following list of facts, each fact is listed within the <facts><fact><statement> XML tags.\n",
    "Each fact also has a document reference to where the fact was extracted from in <facts><fact><reference>.\n",
    "In the answer, list the references that were used.\n",
    "<facts>\n",
    "\"\"\"\n",
    "\n",
    "for statement in statements:\n",
    "    prompt = prompt + \"<fact><statement>\" + statement[0] + \"</statement><reference>\" + reference_dict[statement[1]] + \"</reference>\\n\"\n",
    "    \n",
    "if (len(statements) <= 0):\n",
    "    print(\"\"\"WARNING: No facts were extracted from the Knowledge Graph for this query. The response is pure LLM!\n",
    "    \n",
    "    \"\"\")\n",
    "\n",
    "prompt = prompt + \"\"\"\n",
    "Create a narrative paragraph answering the question below. After the narrative paragraph, include the facts \n",
    "as a bulleted list, but omit all XML tags. Finally, list the references used after the list of facts.\n",
    "\n",
    "Question:\n",
    "\"\"\" + user_question\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"==== Prompt ===\")\n",
    "print(prompt)\n",
    "print(\"==== End Prompt ===\")\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = bedrock_client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "print(model_response[\"content\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

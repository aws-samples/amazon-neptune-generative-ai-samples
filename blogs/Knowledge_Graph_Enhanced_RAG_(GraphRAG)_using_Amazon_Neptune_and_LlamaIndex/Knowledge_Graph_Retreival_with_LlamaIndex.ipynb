{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17bfbd6e-94fb-43dd-996d-268c6130384d",
   "metadata": {},
   "source": [
    "# Knowledge Graph Retrieval using Amazon Neptune and LlamaIndex\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we are going to demonstrate how you can leverage [LlamaIndex](https://www.llamaindex.ai/), and specifically the [Property Graph Index](https://docs.llamaindex.ai/en/stable/examples/property_graph/property_graph_basic/) feature to perform knowledge graph retrieval with Amazon Neptune.  Let's start by taking a look at the two main components here: LlamaIndex and Knowledge Graph Retrieval.\n",
    "\n",
    "LlamaIndex is a data structure and tooling designed to create and interact with large language model indexes. It facilitates the storage, searching, and querying of textual data using advanced vector database techniques in conjunction with large language models like GPT. This enables efficient and effective retrieval of relevant information from extensive text corpora.\n",
    "\n",
    "Natural language querying allows users to interact with computer systems using everyday human language, rather than having to learn and use structured query languages or complex programming commands. This capability enables users to ask questions or provide instructions in their native tongue, and the system can then process this input to understand the user's intent and provide relevant information or perform the requested action.\n",
    "\n",
    "However, in many real-world applications, it is not safe or appropriate to allow users to ask completely open-ended questions of a data set. For example, in a banking application, you may want to give users the ability to ask about their own transactions and account balance, but you certainly wouldn't want to allow them to inquire about other users' financial information.\n",
    "\n",
    "To address these types of use cases, we can leverage a technique called Knowledge Graph Retrieval. Here, a large language model (LLM) is used to extract key entities from the user's natural language question. These extracted entities are then used as the parameters for a pre-defined, templated query. This approach gives the application developer the freedom to create optimized, secure queries with appropriate data access controls, while still providing users with a natural language interface on top of the underlying data.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "For this notebook we will be using Amazon Neptune Database as our data store so you must have a Neptune Database configured.  The methodology presented here will also work with Neptune Analytics and we will call out where the code differs.  This notebook will also require permissions to run Amazon Bedrock models, specifically `Claude v3 Sonnet` and `Titan Embedding v1`.\n",
    "\n",
    "### Installing our dependencies\n",
    "\n",
    "Run the next cell to install the core LlamaIndex packages as well as the specific package for Amazon Neptune and Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283cf1fa-1429-4327-aab2-290041e825df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index llama-index-graph-stores-neptune llama-index-llms-bedrock llama-index-embeddings-bedrock "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82b87d-8a2a-4102-99a0-510e21449cbd",
   "metadata": {},
   "source": [
    "### Loading your Data\n",
    "\n",
    "The data we will use in this notebook is based on the data in *[Graph Databases in Action](https://www.manning.com/books/graph-databases-in-action?a_aid=bechberger)* by Manning Publications. The book uses the most common graph access patterns to build a fictitious application, DiningByFriends, that uses friends and ratings to provide personalized restaurant recommendations.\n",
    "\n",
    "In the following notebook, we demonstrate how to use LlamaIndex and Amazon Neptune to build the queries for the DiningByFriends app using Natural Language questions instead of explicitly writing the queries.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876d4604-4bea-4de6-af1a-04b4e6aad48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4741ca37464d8fa713c4454e0112b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Source type:', options=('', 'samples', 'custom'), style=DescriptionStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17cf0a151fa4ee9ad3b3721c6f00dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data model:', layout=Layout(display='none', visibility='hidden'), options=('', 'property…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49fa4a51d7244f6bb96bcc49f101d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Language:', layout=Layout(display='none', visibility='hidden'), options=('', 'opencypher…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91b0b5695af4123b7792e04ad26f902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Language:', layout=Layout(display='none', visibility='hidden'), options=('', 'opencypher…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec6bca2446b4b0c823ddcb3363b9fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data set:', layout=Layout(display='none', visibility='hidden'), options=(), style=Descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5811bbd2e2fe4b719492d4bc2ad51175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Full File Query:', index=1, layout=Layout(display='none', visibility='hidden'), options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee32ebda9f1a498296a8a72b7ebf2a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Location:', layout=Layout(display='none', visibility='hidden'), options=('Local', 'S3'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e969bb7978492faa6c56e5d8064976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/ec2-user/SageMaker', filename='', title='', show_hidden=False, select_desc='Select', c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f458db6ffe2d4097a6343b9f9da09aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Source:', placeholder='path/to/seedfiles/directory', style=Descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', layout=Layout(visibility='hidden'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13335f60a3654826831b58adff26a49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b00a7bdf6f4c8f80b1a4edb6f4d974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%seed --model property_graph --language gremlin --dataset dining_by_friends --run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5e9b6-f861-4e02-a235-c5ed0a8aeaa4",
   "metadata": {},
   "source": [
    "## Setting up our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79b5a5d-51ee-43a0-8dca-9ea95e2eace1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "\n",
    "\n",
    "# Setup LlamaIndex to use Claude V3 Sonnet for the LLM\n",
    "llm = Bedrock(model=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "# Create the embedding model, this is required by the Property Graph\n",
    "embed_model = BedrockEmbedding(model=\"amazon.titan-embed-text-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2a3dd7-13ea-4e37-80c9-81f927574e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2af2d-1582-44ae-bd95-9b4fbd434337",
   "metadata": {},
   "source": [
    "## Setting up our GraphStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e19cb2-7d20-41e6-b566-c7d7d9ecd69d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neptune import NeptuneDatabasePropertyGraphStore\n",
    "import graph_notebook as gn\n",
    "\n",
    "# Retrieve the configuration of the notebook to get the current host\n",
    "config = gn.configuration.get_config.get_config()\n",
    "\n",
    "graph_store = NeptuneDatabasePropertyGraphStore(host=config.host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd821f96-00ab-4cef-9f6a-06b0a47e2d01",
   "metadata": {},
   "source": [
    "## Setting up our Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091399d5-3777-4a37-a4f8-a9032cf66147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    property_graph_store=graph_store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123df40-0b49-40cd-bdac-609ad2e97a60",
   "metadata": {},
   "source": [
    "## Setting up our Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3957fed5-45f0-4eb2-bd4b-5e37d932f1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import CypherTemplateRetriever\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "\n",
    "class TemplateParams(BaseModel):\n",
    "    \"\"\"Template params for a cypher query.\"\"\"\n",
    "\n",
    "    names: list[str] = Field(\n",
    "        description=\"A list of person names to use for lookup in a knowledge graph.\"\n",
    "    )\n",
    "\n",
    "# Friends Query\n",
    "cypher_query = \"\"\"\n",
    "MATCH (p1:person)-[:friends]->(p) \n",
    "WHERE p1.first_name in $names\n",
    "RETURN p.first_name\"\"\"\n",
    "\n",
    "retriever = CypherTemplateRetriever(index.property_graph_store, TemplateParams, cypher_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676b7c8-6432-4869-9432-13c0f0cba33c",
   "metadata": {},
   "source": [
    "## Querying our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddb7de4-6c0f-4b18-9fb3-fbbaba513735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'p.first_name': 'Kelly'}, {'p.first_name': 'Jim'}, {'p.first_name': 'Josh'}, {'p.first_name': 'Hank'}]\n"
     ]
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"Who are Dave's Friends?\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321a6c74-7f7b-4aef-82f3-db532821bc5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'p': [{'~id': '10', '~entityType': 'node', '~labels': ['person'], '~properties': {'person_id': 1, 'last_name': 'Bech', 'first_name': 'Dave'}}, {'~id': '55', '~entityType': 'relationship', '~start': '10', '~end': '30', '~type': 'friends', '~properties': {}}, {'~id': '30', '~entityType': 'node', '~labels': ['person'], '~properties': {'person_id': 5, 'last_name': 'Gorman', 'first_name': 'Kelly'}}, {'~id': '56', '~entityType': 'relationship', '~start': '30', '~end': '45', '~type': 'friends', '~properties': {}}, {'~id': '45', '~entityType': 'node', '~labels': ['person'], '~properties': {'person_id': 8, 'last_name': 'Mande', 'first_name': 'Denise'}}]}]\n"
     ]
    }
   ],
   "source": [
    "# Connected Friends Query\n",
    "cypher_query = \"\"\"\n",
    "MATCH p=(src:person {first_name:$from_person})-[:friends*1..]-(dst:person {first_name:$to_person})\n",
    "RETURN p LIMIT 1\"\"\"\n",
    "\n",
    "class TemplateParams(BaseModel):\n",
    "    \"\"\"Template params for a cypher query.\"\"\"\n",
    "\n",
    "    from_person: str = Field(\n",
    "        description=\"A person names to start for lookup in a knowledge graph.\"\n",
    "    )\n",
    "    to_person: str = Field(\n",
    "        description=\"A person names to end for lookup in a knowledge graph.\"\n",
    "    )\n",
    "\n",
    "retriever = CypherTemplateRetriever(index.property_graph_store, TemplateParams, cypher_query)\n",
    "\n",
    "nodes = retriever.retrieve(\"Are Dave and Denise connected?\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a357fcb2-f671-417c-8a4f-d19df7647fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'r.name': 'All Night Long', 'rev.rating': 4}, {'r.name': 'Northern Quench', 'rev.rating': 4}, {'r.name': 'Northern Quench', 'rev.rating': 4}, {'r.name': 'Satiated', 'rev.rating': 4}, {'r.name': 'Satiated', 'rev.rating': 4}, {'r.name': 'Without Chaser', 'rev.rating': 4}]\n"
     ]
    }
   ],
   "source": [
    "cypher_query = \"\"\"\n",
    "MATCH (p:person {first_name: $from_person})-[:lives]->(c:city)<-[:within]-(r:restaurant)-[:serves]->(cuisine:cuisine)\n",
    "WHERE cuisine.name IN $cusines\n",
    "MATCH (r)<-[a:about]-(rev:review)\n",
    "WITH r, max(rev.rating) AS max_rating\n",
    "MATCH (r)<-[a:about]-(rev:review)\n",
    "WHERE rev.rating = max_rating\n",
    "RETURN r.name, rev.rating\n",
    "ORDER BY r.name\"\"\"\n",
    "\n",
    "class TemplateParams(BaseModel):\n",
    "    \"\"\"Template params for a cypher query.\"\"\"\n",
    "\n",
    "    from_person: str = Field(\n",
    "        description=\"A person names to start for lookup in a knowledge graph.\"\n",
    "    )\n",
    "    cusines: list[str] = Field(\n",
    "        description=\"Cuisine names for restaurant types to lookup in a knowledge graph.\"\n",
    "    )\n",
    "\n",
    "retriever = CypherTemplateRetriever(index.property_graph_store, TemplateParams, cypher_query)\n",
    "\n",
    "nodes = retriever.retrieve(\"What restaurants near Dave with a diner or bar cuisine is the highest rated?\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
